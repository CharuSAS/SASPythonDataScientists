{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ready for a buzzworthy event as we bring together our beloved bees and scientifc names in a data-driven dance! Today, weâ€™re not just talking about pollen and nectarâ€”weâ€™re talking about the sweet harmony of concatenating bee data and then merging them into one vibrant dataset.\n",
    "\n",
    "Just like a bee flits from blossom to blossom, weâ€™ll be combining our datasets to create a hive of insights. Whether itâ€™s matching the perfect pollinator with its scientific namesake or finding out where the buzz is really happening, this bee-floral fusion will reveal the secrets of the garden in ways weâ€™ve never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55259/2137453403.py:3: DtypeWarning: Columns (6,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1=pd.read_csv('/workspaces/myfolder/SASPythonDataScientists/pattern_decline_N_American_Bumblebees.csv', encoding='latin-1')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1=pd.read_csv('/workspaces/myfolder/SASPythonDataScientists/pattern_decline_N_American_Bumblebees.csv', encoding='latin-1')\n",
    "df2=pd.read_csv('/workspaces/myfolder/SASPythonDataScientists/pattern_decline_Mexican_Bumblebees.csv' , encoding='latin-1')\n",
    "df3=pd.read_csv('/workspaces/myfolder/SASPythonDataScientists/Bumblebee_Others_Scientific_Common_Names.csv' , encoding='latin-1')\n",
    "df4=pd.read_csv('/workspaces/myfolder/SASPythonDataScientists/native_vs_nonnative_bumblebee_sighting_pollinators_of_farm_data_for_publication.csv' , encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenate 2 data frames to combine North American(excluding Alaska) and Mexican Bumblebees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a quick look at the dimensions of the 2 dataframes we are about to concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66907, 26)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# North American bumblebee decline dataframe\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 26)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mexican bumblebee decline dataframe\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation is a way to stitch dataframes along an axis, either row axis or column axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use concat() and pass it a list of DataFrames that you want to concatenate. Code for this task below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfconc=pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66931, 26)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfconc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're diving into the world of bumblebees by buzzing through some data magic in Python! Imagine we've got one table that's packed with the common names of our favorite fuzzy pollinators, and another that's got their nesting habits. By merging the common names  with the nesting habits names into one tidy table, we're basically creating the ultimate bee databaseâ€”bringing together the familiar and the formal. It's like giving each bee its proper name tag at the hive party! This way, we can easily connect the dots between the Latin and the layman's terms, making our bumblebee data analysis as sweet as honey. ðŸðŸ’»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a quick look at the dimensions of the tables we are about to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with our two bumblebee tablesâ€”one buzzing with scientific names and the other humming with common namesâ€”Python's merge() function is like a matchmaker for your data. The great thing about merge() is that it lets you decide exactly how these two tables come together. Say you want to merge them based on the ScientificName column, ensuring that each bee's formal identity pairs up perfectly with its everyday nickname. By using the on parameter, you can create the ultimate bee directory where the Latin meets the common, all while keeping your data as sharp as a bee's stinger! ðŸðŸ”—"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qIn the world of pandas, DataFrames have a merge() method,  with similar functionality to SAS joins. No need to sort ahead of timeâ€”perform all kinds of different joins by simply using the how keyword. Itâ€™s like a hive of possibilities for your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SCIENTIFICNAME'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55259/3012165160.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minner_join\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfconc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SCIENTIFICNAME\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inner\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib64/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10828\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10829\u001b[0m     ) -> DataFrame:\n\u001b[1;32m  10830\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10832\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10835\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SCIENTIFICNAME'"
     ]
    }
   ],
   "source": [
    "inner_join = dfconc.merge(df3, on=[\"SCIENTIFICNAME\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " column names for dataframes are case sensitive.\n",
    "\n",
    "Dataframe column names are essentially string values, which are case sensitive in Python. Because of this, you will need to be careful whenever you utilize column names, such as when renaming a column, accessing columns or performing functions on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfconc.columns = dfconc.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'institutioncode',\n",
       " 'collectioncode',\n",
       " 'basisofrecord',\n",
       " 'occurrenceid',\n",
       " 'catalognumber',\n",
       " 'recordedby',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'country',\n",
       " 'stateprovince',\n",
       " 'county',\n",
       " 'locality',\n",
       " 'verbatimlatitude',\n",
       " 'verbatimlongitude',\n",
       " 'identifiedby',\n",
       " 'scientificname',\n",
       " 'kingdom',\n",
       " 'phylum',\n",
       " 'class',\n",
       " 'order',\n",
       " 'family',\n",
       " 'genus',\n",
       " 'specificepithet',\n",
       " 'scientificnameauthorship']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dfconc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns = df3.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scientificname',\n",
       " 'species',\n",
       " 'specificepithet',\n",
       " 'commonname',\n",
       " 'description',\n",
       " 'source']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inner = dfconc.merge(df3, on=[\"scientificname\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of           id institutioncode collectioncode      basisofrecord  occurrenceid  \\\n",
       "0          1        USDA-ARS           BBSL  PreservedSpecimen   699384987.0   \n",
       "1          2        USDA-ARS           BBSL  PreservedSpecimen   699384988.0   \n",
       "2          3        USDA-ARS           BBSL  PreservedSpecimen   699384989.0   \n",
       "3          4        USDA-ARS           BBSL  PreservedSpecimen   699384990.0   \n",
       "4          5        USDA-ARS           BBSL  PreservedSpecimen   699384991.0   \n",
       "...      ...             ...            ...                ...           ...   \n",
       "66926  66927        USDA-ARS           BBSL  PreservedSpecimen           NaN   \n",
       "66927  66928        USDA-ARS           BBSL  PreservedSpecimen           NaN   \n",
       "66928  66929        USDA-ARS           BBSL  PreservedSpecimen           NaN   \n",
       "66929  66930        USDA-ARS           BBSL  PreservedSpecimen           NaN   \n",
       "66930  66931        USDA-ARS           BBSL  PreservedSpecimen           NaN   \n",
       "\n",
       "      catalognumber        recordedby    year  month   day  ...        order  \\\n",
       "0        BBSL221088       W. Apperson  1970.0    7.0  27.0  ...  Hymenoptera   \n",
       "1        BBSL241571       W. Apperson  1970.0    7.0  27.0  ...  Hymenoptera   \n",
       "2             76122         B. Hevron  1989.0    6.0  16.0  ...  Hymenoptera   \n",
       "3          JPS30053  P.S. Bartholomew  1970.0    9.0  15.0  ...  Hymenoptera   \n",
       "4        BBSL226571       W.J. Hanson  1961.0    8.0  15.0  ...  Hymenoptera   \n",
       "...             ...               ...     ...    ...   ...  ...          ...   \n",
       "66926    BOMBUS1219               NaN  1928.0    8.0  19.0  ...  Hymenoptera   \n",
       "66927    BOMBUS1348               NaN  1928.0    7.0  13.0  ...  Hymenoptera   \n",
       "66928   BOMBUS33485               NaN  1930.0    9.0  13.0  ...  Hymenoptera   \n",
       "66929   BOMBUS33755               NaN  1944.0    1.0   8.0  ...  Hymenoptera   \n",
       "66930   BOMBUS37213               NaN  1933.0    6.0  19.0  ...  Hymenoptera   \n",
       "\n",
       "       family   genus specificepithet_x  scientificnameauthorship  species  \\\n",
       "0      Apidae  Bombus      occidentalis               Greene 1858   Bombus   \n",
       "1      Apidae  Bombus      occidentalis               Greene 1858   Bombus   \n",
       "2      Apidae  Bombus          bifarius              Cresson 1878   Bombus   \n",
       "3      Apidae  Bombus      occidentalis               Greene 1858   Bombus   \n",
       "4      Apidae  Bombus          bifarius              Cresson 1878   Bombus   \n",
       "...       ...     ...               ...                       ...      ...   \n",
       "66926  Apidae  Bombus     pensylvanicus             (DeGeer 1773)   Bombus   \n",
       "66927  Apidae  Bombus     pensylvanicus             (DeGeer 1773)   Bombus   \n",
       "66928  Apidae  Bombus     pensylvanicus             (DeGeer 1773)   Bombus   \n",
       "66929  Apidae  Bombus     pensylvanicus             (DeGeer 1773)   Bombus   \n",
       "66930  Apidae  Bombus         impatiens              Cresson 1863   Bombus   \n",
       "\n",
       "      specificepithet_y                commonname  \\\n",
       "0          occidentalis         Western Bumblebee   \n",
       "1          occidentalis         Western Bumblebee   \n",
       "2              bifarius        Two-form Bumblebee   \n",
       "3          occidentalis         Western Bumblebee   \n",
       "4              bifarius        Two-form Bumblebee   \n",
       "...                 ...                       ...   \n",
       "66926     pensylvanicus        American Bumblebee   \n",
       "66927     pensylvanicus        American Bumblebee   \n",
       "66928     pensylvanicus        American Bumblebee   \n",
       "66929     pensylvanicus        American Bumblebee   \n",
       "66930         impatiens  Common Eastern Bumblebee   \n",
       "\n",
       "                                             description  \\\n",
       "0      Found in western U.S.; enjoys wildflowers and ...   \n",
       "1      Found in western U.S.; enjoys wildflowers and ...   \n",
       "2      Found in various North American habitats; enjo...   \n",
       "3      Found in western U.S.; enjoys wildflowers and ...   \n",
       "4      Found in various North American habitats; enjo...   \n",
       "...                                                  ...   \n",
       "66926  Found across North America; enjoys a wide rang...   \n",
       "66927  Found across North America; enjoys a wide rang...   \n",
       "66928  Found across North America; enjoys a wide rang...   \n",
       "66929  Found across North America; enjoys a wide rang...   \n",
       "66930  Found in eastern U.S.; enjoys a wide range of ...   \n",
       "\n",
       "                            source  \n",
       "0                    IUCN Red List  \n",
       "1                    IUCN Red List  \n",
       "2      Bumblebees of North America  \n",
       "3                    IUCN Red List  \n",
       "4      Bumblebees of North America  \n",
       "...                            ...  \n",
       "66926  Bumblebees of North America  \n",
       "66927  Bumblebees of North America  \n",
       "66928  Bumblebees of North America  \n",
       "66929  Bumblebees of North America  \n",
       "66930  Bumblebees of North America  \n",
       "\n",
       "[66931 rows x 31 columns]>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inner.describe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Workbench Python",
   "language": "python",
   "name": "workbench_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
