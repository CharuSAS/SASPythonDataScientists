{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAS Data Science Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access - Identify analysis tables that will be used in load those tables.<br> \n",
    "Explore/Investigate - Inspect tables to determine whether any changes are needed for data items due to data inconsistencies or data quality issues, as well as identify any new data items that need to be calculated. <br>\n",
    "Prepare - Correct any data quality issues and create any new calculated items needed for analysis. <br>\n",
    "Analyze - Explore  data to identify any patterns, relationships, and trends. <br>\n",
    "Report - Develop interactive reports that can be shared via the web or a mobile device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12706/203958902.py:3: DtypeWarning: Columns (7,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1=pd.read_csv('/workspaces/myfolder/SASPythonDataScientists/pattern_decline_NAmerican_Bumblebees.csv', encoding='latin-1')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1=pd.read_csv('/workspaces/myfolder/SASPythonDataScientists/pattern_decline_NAmerican_Bumblebees.csv', encoding='latin-1')\n",
    "df2=pd.read_csv('/workspaces/myfolder/SASPythonDataScientists/pattern_decline__Mexican_Bumblebees.csv' , encoding='latin-1')\n",
    "df3=pd.read_csv('/workspaces/myfolder/SASPythonDataScientists/Bumblebee_Others_Scientific_Common_Names.csv' , encoding='latin-1')\n",
    "df4=pd.read_csv('/workspaces/myfolder/SASPythonDataScientists/native_vs_nonnative_bumblebee_sighting_pollinators_of_farm_data_for_publication.csv' , encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas describe() to view a statistical summary of a dataframe like percentile, mean, std, etc. of a data frame or a series of numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 25 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   id                        24 non-null     int64  \n",
      " 1   institutionCode           24 non-null     object \n",
      " 2   collectionCode            24 non-null     object \n",
      " 3   basisOfRecord             24 non-null     object \n",
      " 4   informationWithheld       0 non-null      float64\n",
      " 5   occurrenceID              24 non-null     int64  \n",
      " 6   catalogNumber             24 non-null     object \n",
      " 7   year                      24 non-null     int64  \n",
      " 8   month                     24 non-null     int64  \n",
      " 9   day                       24 non-null     int64  \n",
      " 10  country                   24 non-null     object \n",
      " 11  stateProvince             24 non-null     object \n",
      " 12  locality                  23 non-null     object \n",
      " 13  verbatimLatitude          23 non-null     float64\n",
      " 14  verbatimLongitude         23 non-null     float64\n",
      " 15  scientificName            24 non-null     object \n",
      " 16  kingdom                   24 non-null     object \n",
      " 17  phylum                    24 non-null     object \n",
      " 18  class                     24 non-null     object \n",
      " 19  order                     24 non-null     object \n",
      " 20  family                    24 non-null     object \n",
      " 21  genus                     24 non-null     object \n",
      " 22  specificEpithet           24 non-null     object \n",
      " 23  scientificNameAuthorship  24 non-null     object \n",
      " 24  vernacularName            0 non-null      float64\n",
      "dtypes: float64(4), int64(5), object(16)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#metadata\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method info() provides technical information about a DataFrame, so let‚Äôs view the output in more detail:\n",
    "\n",
    "df2 is a DataFrame.\n",
    "\n",
    "There are 24  entries, i.e. 24  rows.\n",
    "\n",
    "Each row has a row label (aka the index) with values ranging from 0 to  0 to 23.\n",
    "\n",
    "The table has 25 columns. Most columns have a value for each of the rows (all  values are non-null). \n",
    "\n",
    "There are some columns with textual data (strings, aka object). The other columns are numerical data with some of them whole numbers (aka integer) and others are real numbers (aka float).\n",
    "\n",
    "The kind of data (characters, integers,‚Ä¶) in the different columns are summarized by listing the dtypes.\n",
    "\n",
    "The approximate amount of RAM used to hold the DataFrame is provided as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>institutionCode</th>\n",
       "      <th>collectionCode</th>\n",
       "      <th>basisOfRecord</th>\n",
       "      <th>informationWithheld</th>\n",
       "      <th>occurrenceID</th>\n",
       "      <th>catalogNumber</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>scientificName</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>phylum</th>\n",
       "      <th>class</th>\n",
       "      <th>order</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>specificEpithet</th>\n",
       "      <th>scientificNameAuthorship</th>\n",
       "      <th>vernacularName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767110452</td>\n",
       "      <td>USDA-ARS</td>\n",
       "      <td>BBSL</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767110452</td>\n",
       "      <td>BOMBUS1055</td>\n",
       "      <td>1965</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>Bombus pensylvanicus</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Arthropoda</td>\n",
       "      <td>Insecta</td>\n",
       "      <td>Hymenoptera</td>\n",
       "      <td>Apidae</td>\n",
       "      <td>Bombus</td>\n",
       "      <td>pensylvanicus</td>\n",
       "      <td>(DeGeer 1773)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767110527</td>\n",
       "      <td>USDA-ARS</td>\n",
       "      <td>BBSL</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767110527</td>\n",
       "      <td>BOMBUS1062</td>\n",
       "      <td>1928</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>Bombus pensylvanicus</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Arthropoda</td>\n",
       "      <td>Insecta</td>\n",
       "      <td>Hymenoptera</td>\n",
       "      <td>Apidae</td>\n",
       "      <td>Bombus</td>\n",
       "      <td>pensylvanicus</td>\n",
       "      <td>(DeGeer 1773)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>767110538</td>\n",
       "      <td>USDA-ARS</td>\n",
       "      <td>BBSL</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767110538</td>\n",
       "      <td>BOMBUS1063</td>\n",
       "      <td>1928</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>Bombus pensylvanicus</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Arthropoda</td>\n",
       "      <td>Insecta</td>\n",
       "      <td>Hymenoptera</td>\n",
       "      <td>Apidae</td>\n",
       "      <td>Bombus</td>\n",
       "      <td>pensylvanicus</td>\n",
       "      <td>(DeGeer 1773)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>767110549</td>\n",
       "      <td>USDA-ARS</td>\n",
       "      <td>BBSL</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767110549</td>\n",
       "      <td>BOMBUS1064</td>\n",
       "      <td>1928</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Bombus pensylvanicus</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Arthropoda</td>\n",
       "      <td>Insecta</td>\n",
       "      <td>Hymenoptera</td>\n",
       "      <td>Apidae</td>\n",
       "      <td>Bombus</td>\n",
       "      <td>pensylvanicus</td>\n",
       "      <td>(DeGeer 1773)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>767110560</td>\n",
       "      <td>USDA-ARS</td>\n",
       "      <td>BBSL</td>\n",
       "      <td>PreservedSpecimen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767110560</td>\n",
       "      <td>BOMBUS1065</td>\n",
       "      <td>1928</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>Bombus pensylvanicus</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Arthropoda</td>\n",
       "      <td>Insecta</td>\n",
       "      <td>Hymenoptera</td>\n",
       "      <td>Apidae</td>\n",
       "      <td>Bombus</td>\n",
       "      <td>pensylvanicus</td>\n",
       "      <td>(DeGeer 1773)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id institutionCode collectionCode      basisOfRecord  \\\n",
       "0  767110452        USDA-ARS           BBSL  PreservedSpecimen   \n",
       "1  767110527        USDA-ARS           BBSL  PreservedSpecimen   \n",
       "2  767110538        USDA-ARS           BBSL  PreservedSpecimen   \n",
       "3  767110549        USDA-ARS           BBSL  PreservedSpecimen   \n",
       "4  767110560        USDA-ARS           BBSL  PreservedSpecimen   \n",
       "\n",
       "   informationWithheld  occurrenceID catalogNumber  year  month  day  ...  \\\n",
       "0                  NaN     767110452    BOMBUS1055  1965      8   11  ...   \n",
       "1                  NaN     767110527    BOMBUS1062  1928      8   26  ...   \n",
       "2                  NaN     767110538    BOMBUS1063  1928      8   21  ...   \n",
       "3                  NaN     767110549    BOMBUS1064  1928      8    5  ...   \n",
       "4                  NaN     767110560    BOMBUS1065  1928      8   19  ...   \n",
       "\n",
       "         scientificName   kingdom      phylum    class        order  family  \\\n",
       "0  Bombus pensylvanicus  Animalia  Arthropoda  Insecta  Hymenoptera  Apidae   \n",
       "1  Bombus pensylvanicus  Animalia  Arthropoda  Insecta  Hymenoptera  Apidae   \n",
       "2  Bombus pensylvanicus  Animalia  Arthropoda  Insecta  Hymenoptera  Apidae   \n",
       "3  Bombus pensylvanicus  Animalia  Arthropoda  Insecta  Hymenoptera  Apidae   \n",
       "4  Bombus pensylvanicus  Animalia  Arthropoda  Insecta  Hymenoptera  Apidae   \n",
       "\n",
       "    genus specificEpithet scientificNameAuthorship vernacularName  \n",
       "0  Bombus   pensylvanicus            (DeGeer 1773)            NaN  \n",
       "1  Bombus   pensylvanicus            (DeGeer 1773)            NaN  \n",
       "2  Bombus   pensylvanicus            (DeGeer 1773)            NaN  \n",
       "3  Bombus   pensylvanicus            (DeGeer 1773)            NaN  \n",
       "4  Bombus   pensylvanicus            (DeGeer 1773)            NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the first 5 rows of df1 using the head method\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>informationWithheld</th>\n",
       "      <th>occurrenceID</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>verbatimLatitude</th>\n",
       "      <th>verbatimLongitude</th>\n",
       "      <th>vernacularName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.671143e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.671143e+08</td>\n",
       "      <td>1940.12500</td>\n",
       "      <td>7.208333</td>\n",
       "      <td>14.541667</td>\n",
       "      <td>21.707561</td>\n",
       "      <td>-97.566572</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.995903e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.995903e+03</td>\n",
       "      <td>20.28774</td>\n",
       "      <td>2.084710</td>\n",
       "      <td>7.824039</td>\n",
       "      <td>5.250579</td>\n",
       "      <td>6.877705</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.671105e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.671105e+08</td>\n",
       "      <td>1908.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.066010</td>\n",
       "      <td>-104.372970</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.671106e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.671106e+08</td>\n",
       "      <td>1928.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>19.246470</td>\n",
       "      <td>-99.376860</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.671106e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.671106e+08</td>\n",
       "      <td>1928.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>19.246470</td>\n",
       "      <td>-99.101350</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.671120e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.671120e+08</td>\n",
       "      <td>1962.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>21.932640</td>\n",
       "      <td>-99.101350</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.671401e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.671401e+08</td>\n",
       "      <td>1984.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>37.269540</td>\n",
       "      <td>-76.015210</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  informationWithheld  occurrenceID        year      month  \\\n",
       "count  2.400000e+01                  0.0  2.400000e+01    24.00000  24.000000   \n",
       "mean   7.671143e+08                  NaN  7.671143e+08  1940.12500   7.208333   \n",
       "std    8.995903e+03                  NaN  8.995903e+03    20.28774   2.084710   \n",
       "min    7.671105e+08                  NaN  7.671105e+08  1908.00000   1.000000   \n",
       "25%    7.671106e+08                  NaN  7.671106e+08  1928.00000   7.000000   \n",
       "50%    7.671106e+08                  NaN  7.671106e+08  1928.00000   8.000000   \n",
       "75%    7.671120e+08                  NaN  7.671120e+08  1962.00000   8.000000   \n",
       "max    7.671401e+08                  NaN  7.671401e+08  1984.00000   9.000000   \n",
       "\n",
       "             day  verbatimLatitude  verbatimLongitude  vernacularName  \n",
       "count  24.000000         23.000000          23.000000             0.0  \n",
       "mean   14.541667         21.707561         -97.566572             NaN  \n",
       "std     7.824039          5.250579           6.877705             NaN  \n",
       "min     1.000000         17.066010        -104.372970             NaN  \n",
       "25%     7.750000         19.246470         -99.376860             NaN  \n",
       "50%    14.000000         19.246470         -99.101350             NaN  \n",
       "75%    19.500000         21.932640         -99.101350             NaN  \n",
       "max    30.000000         37.269540         -76.015210             NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary statistics\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      24.00000\n",
       "mean     1940.12500\n",
       "std        20.28774\n",
       "min      1908.00000\n",
       "25%      1928.00000\n",
       "50%      1928.00000\n",
       "75%      1962.00000\n",
       "max      1984.00000\n",
       "Name: year, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate some descriptive statistics for one column, year\n",
    "df2['year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get frequency counts, create a value_counts dict with an entry for each col in df2, where each key is the column anme and each value is a series containing\n",
    "the value counts for that column.\n",
    "method:value_counts\n",
    "for col in df2.columns = loop iterates over each column name & returnes a list-like object with all column names in df2\n",
    "value_counts = {col: df2[col].value_counts() for col in df2.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display just the 2 columns and 20 rows from df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[['ScientificName','CommonName']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenating 2 data frames to combine North American(excluding Alaska) and Mexican Bumblebees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### great explanation https://realpython.com/pandas-merge-join-and-concat/\n",
    "https://pandas.pydata.org/docs/user_guide/merging.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbig=pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dfbig.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for north american bumblebees minus alaska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnoal=dfbig[dfbig['stateProvince'] !='Alaska' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dfnoal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dfnoal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnoal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnoal['scientificName'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Filtering Rows Based on a Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering rows based on a condition is a common data management task that allows you to focus on a specific subset of your data. By applying a condition to a column, such as selecting rows where the pollinator_genus is Bumblebee, you can isolate and analyze the data that meets your criteria. This helps in drawing insights and making data-driven decisions based on relevant data subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Scientific common names CSV file into a DataFrame for easy data manipulation and analysis.\n",
    "df4=pd.read_csv('/workspaces/myfolder/SASPythonDataScientists/native_vs_nonnative_bumblebee_sighting_pollinators_of_farm_data_for_publication.csv' , encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where \n",
    "filtered_df = df4.query('Species == \"Bombus\"')\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print creates a basic looking output, use df.head etc. instead\n",
    "python is object oriented, so every line of code uses an object.\n",
    "following cell is indexing. df is the dataframe. df[1] selects first row, df[1,2] selects first row, 2nd col; df[0:10, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[df4['Species'] == 'Bombus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['Species'] == 'Bombus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df4['Species'] == 'Bombus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(~(df4['Species'] == 'Bombus'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((df4['Species'] != 'Bombus'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're diving into the world of bumblebees by buzzing through some data magic in Python! Imagine we've got one table that's packed with the common names of our favorite fuzzy pollinators, and another that's got their nesting habits. By merging the common names  with the nesting habits names into one tidy table, we're basically creating the ultimate bee database‚Äîbringing together the familiar and the formal. It's like giving each bee its proper name tag at the hive party! This way, we can easily connect the dots between the Latin and the layman's terms, making our bumblebee data analysis as sweet as honey. üêùüíª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a quick look at the dimensions of the tables we are about to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with our two bumblebee tables‚Äîone buzzing with scientific names and the other humming with common names‚ÄîPython's merge() function is like a matchmaker for your data. The great thing about merge() is that it lets you decide exactly how these two tables come together. Say you want to merge them based on the ScientificName column, ensuring that each bee's formal identity pairs up perfectly with its everyday nickname. By using the on parameter, you can create the ultimate bee directory where the Latin meets the common, all while keeping your data as sharp as a bee's stinger! üêùüîó"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qIn the world of pandas, DataFrames have a merge() method,  with similar functionality to SAS joins. No need to sort ahead of time‚Äîperform all kinds of different joins by simply using the how keyword. It‚Äôs like a hive of possibilities for your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_merged = pd.merge(df3, df4, on=[\"SPECIES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_join = df1.merge(df3, on=[\"SCIENTIFICNAME\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " column names for dataframes are case sensitive.\n",
    "\n",
    "Dataframe column names are essentially string values, which are case sensitive in Python. Because of this, you will need to be careful whenever you utilize column names, such as when renaming a column, accessing columns or performing functions on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns = df3.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.columns = df4.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inner = df3.merge(df4, on=[\"species\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inner[['scientificname','commonname', 'nesting']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inner.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge df1 and df3 on column scientificname to see where bombus nests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df3, df4, on=[\"species\"])\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get me the all the Bombus species with nesting values -start here & clean up story around merging & concatenating\n",
    "merged[['Species'] == 'Bombus','nesting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the native vs non native bumblebee CSV file into a DataFrame for easy data manipulation and analysis.\n",
    "df5=pd.read_csv('/workspaces/myfolder/SASPythonDataScientists/native_vs_nonnative_bumblebee_sighting_pollinators_of_farm_data_for_publication.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.describe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping Aggregating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keep columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbig = dfbig[['scientificName','stateProvince']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/47320572/pandas-groupby-and-count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbig.groupby(['stateProvince','scientificName'])['scientificName'].count().head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chaining, create an obj with syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbig.value_counts(subset=['scientificName', 'stateProvince']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbig.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dfbig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get to know data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfbig.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you import data into a Pandas DataFrame, Pandas by default tries to know the data types of each column. Columns with text are by default marked as Object datatype.\n",
    "\n",
    "But Object dtype have a much broader scope. They can not only include strings, but also any other data that Pandas doesn't understand.\n",
    "\n",
    "After Pandas 1.0 (now 1.1.2), there's a dedicated dtype to handle and work with text data, that is, String.ü§î\n",
    "\n",
    "How is this important?\n",
    "\n",
    "When a column is Object type, it does not necessarily mean that all the values will be string.\n",
    "\n",
    "In fact, they can all be numbers, or a mixture of string, integers and floats.\n",
    "\n",
    "With this discrepancy present, you can not do any string operation on the column straightaway.\n",
    "\n",
    "Moreover, having dtype as Object will make it less clear to work with just text and exclude the non-text values.\n",
    "\n",
    "With the new String dtype, the values are explicitly treated as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean(), inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the DataFrame to use best possible dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfconv = dfbig.convert_dtypes()\n",
    "dfconv.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfconv.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Python is a power language, it may not have ready-to-use functions that replicates SAS procedure exactly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, first group by age_category gender, aggregate by statistical functions, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=df1.groupby(['year','month']).agg(['mean','max','min','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=df1.groupby(['year','month']).agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request first 5 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfconv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfconv.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "greedy vs lazy search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all instances of bee names ending in 'en' 'ed' or with a '-' using perl regular expression\n",
    "\n",
    " code to repeat this perl code where prxmatch('/[a-z]ern|ed|-( |^(1))/', commonname);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'[a-z]ern|ed|-( |^(1))'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values Fill missing values with the column mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling missing values is crucial for maintaining data integrity and ensuring accurate analysis. Missing data can be filled using various methods, such as replacing them with the column mean. This task involves using the fillna function to fill any NaN (Not a Number) values in the DataFrame with the mean of their respective columns, thereby preventing potential biases or errors in subsequent analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping Aggregating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a Function to Each Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying a function to each column allows you to perform element-wise operations across the DataFrame. This task involves using the apply function with a lambda function to modify the values in each column. For example, multiplying each element by 2. This technique is useful for standardizing data, performing calculations, and transforming data values as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a lambda function to each column\n",
    "df = df.apply(lambda x: x*2)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting DataFrame to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('cleaned_data.csv', index=False)\n",
    "print(\"DataFrame exported to cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get a python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=df1['column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ari 20aug 24 frequency counts for all categorical variables\n",
    "for loop-instead of looping over index; iterating thro categorical columns\n",
    "column =goes thro each of the list elements\n",
    "display - print -running crosstab method in pandas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables=[]\n",
    "for column in df1.select_dtypes(include=['object']).columns:\n",
    "    tables.append(pd.crosstab(index=df1[column], columns='number of observations'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df1.select_dtypes(include=['object']).columns:\n",
    "    display(pd.crosstab(index=df1[column], columns='number of observations'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df1.select_dtypes(include=['object']).columns:\n",
    "    display(pd.crosstab(index=df1[column], columns='% observations', normalize='columns')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcount=df1.groupby(list(df1)).size()\n",
    "print(\"counts\",dfcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcount=df1.groupby(['country']).size()\n",
    "print(\"counts\",dfcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcount=dfconv.groupby(['country']).size()\n",
    "print(\"counts\",dfcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nunique() method returns the number of unique values for each column.\n",
    "\n",
    "By specifying the column axis (axis='columns'), the nunique() method searches column-wise and returns the number of unique values for each row.\n",
    "\n",
    "Syntax\n",
    "dataframe.nunique(axis, dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfconv.nunique('columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff types is the problem\n",
    "dfconv.apply(lambda x: x.value_counts()).T.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df1.groupby(['country', 'stateProvince', 'scientificName']).size() \n",
    "print(count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = dfconv.groupby(['country', 'stateProvince', 'scientificName']).size() \n",
    "print(count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df['fruit'].value_counts()['apple']\n",
    "\n",
    "print(f\"The number of apples is: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the presence of non-native plant species affect bumblebee populations?\t\t\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame on 'index', 'columns', and 'values'\n",
    "pivot_df = df.pivot(index='date', columns='category', values='value')\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample time series data to monthly frequency\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "monthly_df = df.resample('M').sum()\n",
    "print(monthly_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove duplicate rows based on all columns\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving imported file to workbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# File path and name\n",
    "file_path = r\"/workspaces/myfolder/MachineLearning/hmeq.csv\"\n",
    " \n",
    "# Specify the URL of the CSV file\n",
    "url = r\"https://support.sas.com/documentation/onlinedoc/viya/exampledatasets/hmeq.csv\"\n",
    " \n",
    "# Download the and save CSV file to Workbench\n",
    "response = requests.get(url)\n",
    "with open(file_path, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "    print(f'File downloaded:{file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Workbench Python",
   "language": "python",
   "name": "workbench_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
